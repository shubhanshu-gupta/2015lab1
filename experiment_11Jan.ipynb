{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficients: \\n', array([  1.23952825e-82]))\n",
      "('Intercept: \\n', 310212.21662468516)\n",
      "The mean square error is 34078559824.4\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'Abhishek'\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neighbors\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "from scipy.sparse import hstack,csr_matrix,isspmatrix_csr\n",
    "import re\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rb\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "def splitDataset(dataframe, splitRatio):\n",
    "    msk = np.random.rand(len(dataframe)) < splitRatio\n",
    "    train,test = dataframe[msk],dataframe[~msk]\n",
    "    return (train,test)\n",
    "def extractCollegeStateFeatures(dataframe):\n",
    "    dataValues = dataframe['CollegeState'].values\n",
    "    collegeState_set = set(dataValues)\n",
    "    collegeStateDictionary = dict(enumerate(collegeState_set))\n",
    "    collegeStateList = list(collegeState_set)\n",
    "    featureList = []\n",
    "    for i in range(0,len(dataValues)):\n",
    "        featureList.append(collegeStateList.index(dataValues[i]))\n",
    "\n",
    "    return featureList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetchLabels(dataframe,salaryBar):\n",
    "    labels = []\n",
    "\n",
    "    for salaryValue in dataframe['Salary'].values:\n",
    "        if(salaryValue<=salaryBar[0]):\n",
    "            labels.append(0)\n",
    "        elif(salaryValue>salaryBar[0] and salaryValue<salaryBar[1]):\n",
    "            labels.append(1)\n",
    "        elif(salaryValue>salaryBar[1] and salaryValue<salaryBar[2]):\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(3)\n",
    "    return labels\n",
    "\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,dataframe):\n",
    "        featureSet = []\n",
    "        collegeStateFeatureList = extractCollegeStateFeatures(dataframe)\n",
    "        count = 0\n",
    "        for index,row in dataframe.iterrows():\n",
    "\n",
    "            features = {}\n",
    "            #features['12percentage'] = row['12percentage']\n",
    "            #features['10percentage'] = row['10percentage']\n",
    "\n",
    "            #features['CollegeTier'] = row['CollegeTier']\n",
    "            #features['collegeGPA'] =row['collegeGPA']\n",
    "            features['seriousness'] = math.pow(2.0,float(row[\"10percentage\"] + row[\"12percentage\"] + row[\"collegeGPA\"]))\n",
    "            #features['AMCATscore'] = math.pow(2.0,float(row['English'] + row['Logical'] + row['Quant'])/30.0)\n",
    "            #features['Logical'] = row['Logical']\n",
    "            #features['Quant'] = row['Quant']\n",
    "            # else:\n",
    "            #     features['Degree'] = 0\n",
    "            # if(row['Gender']=='m'):\n",
    "            #     features['Gender'] = 1\n",
    "            # else:\n",
    "            #     features['Gender'] = 0\n",
    "\n",
    "            featureSet.append(features)\n",
    "            count = count + 1\n",
    "        return featureSet\n",
    "\n",
    "def evaluate(salary_actual,salary_predicted):\n",
    "    print \"The mean square error is \"+str(mean_squared_error(salary_actual,salary_predicted))\n",
    "\n",
    "\n",
    "def main(filename):\n",
    "\n",
    "    splitRatio = 0.8\n",
    "\n",
    "    df = pd.read_excel(filename,header=0)\n",
    "\n",
    "\n",
    "    trainingSet, testSet = splitDataset(df, splitRatio)\n",
    "    clf = sklearn.linear_model.LinearRegression()\n",
    "    pipeline = Pipeline([\n",
    "    # Extract the subject & body\n",
    "\n",
    "\n",
    "    # Use FeatureUnion to combine the features from subject and body\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for standard bag-of-words model for body\n",
    "            #('bow', Pipeline([\n",
    "            #    ('count', CountVectorizer()),\n",
    "            #    ('tfidf',TfidfTransformer()),\n",
    "            #])),\n",
    "\n",
    "            # Pipeline for pulling ad hoc features from post's body\n",
    "            ('body_stats', Pipeline([\n",
    "                ('stats', TextStats()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    "\n",
    "        ],\n",
    "\n",
    "        # weight components in FeatureUnion\n",
    "        #transformer_weights={\n",
    "        #    'subject': 0.8,\n",
    "        #    'body_bow': 0.5,\n",
    "        #    'body_stats': 1.0,\n",
    "        #},\n",
    "    )),\n",
    "\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('svc', clf),\n",
    "])\n",
    "\n",
    "    model_name = \"singlelogisticregressionclassifier\"\n",
    "    #clf = sklearn.naive_bayes.MultinomialNB()\n",
    "    #train_classifiers(traincsvfile,clf)\n",
    "    #train_single_classifier(traincsvfile,pipeline,model_name)\n",
    "    predicted_labels = []\n",
    "\n",
    "\n",
    "    def f(x):\n",
    "        return float(x)\n",
    "    f = numpy.vectorize(f)\n",
    "    test_labels = f(testSet['Salary'].values)\n",
    "    train_labels=f(trainingSet['Salary'].values)\n",
    "    x = pipeline.fit(trainingSet,train_labels)\n",
    "    meanvalue = numpy.mean(train_labels)\n",
    "    predicted_labels = numpy.empty(test_labels.shape)\n",
    "    predicted_labels.fill(meanvalue)\n",
    "    #predicted_labels = pipeline.predict(testSet)\n",
    "    #print(\"Intercept:\",clf.)\n",
    "    print('Coefficients: \\n', clf.coef_)\n",
    "    print('Intercept: \\n', clf.intercept_)\n",
    "\n",
    "    evaluate(test_labels,predicted_labels)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"C:\\\\Users\\\\Abhishek\\\\Downloads\\\\datachallenge_cods2016\\\\datachallenge_cods2016\\\\train.xlsx\"\n",
    "    main(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficients: \\n', array([[ -1.58807474e-02],\n",
      "       [ -1.63641553e-02],\n",
      "       [ -1.54565650e-02],\n",
      "       [ -1.49743702e-02],\n",
      "       [ -1.90975909e-02],\n",
      "       [ -1.24954738e-02],\n",
      "       [ -1.52960831e-02],\n",
      "       [ -1.44387674e-02],\n",
      "       [ -1.55066556e-02],\n",
      "       [ -1.22450866e-02],\n",
      "       [ -1.30203453e-02],\n",
      "       [ -1.28582769e-02],\n",
      "       [ -9.92352502e-03],\n",
      "       [ -7.15438023e-03],\n",
      "       [ -9.69197836e-03],\n",
      "       [ -1.00560386e-02],\n",
      "       [ -1.23593311e-02],\n",
      "       [ -6.46691424e-03],\n",
      "       [ -1.53768979e-02],\n",
      "       [ -1.29213095e-02],\n",
      "       [ -1.45499245e-02],\n",
      "       [ -7.72731842e-03],\n",
      "       [ -1.84284591e-02],\n",
      "       [ -6.34245488e-03],\n",
      "       [ -8.57055086e-03],\n",
      "       [ -1.32570949e-02],\n",
      "       [ -1.13231855e-02],\n",
      "       [ -1.25295572e-02],\n",
      "       [ -8.07695638e-03],\n",
      "       [ -1.21587970e-02],\n",
      "       [ -4.69955699e-03],\n",
      "       [ -1.17481205e-02],\n",
      "       [ -1.13281802e-02],\n",
      "       [ -1.12804633e-02],\n",
      "       [ -4.99890498e-03],\n",
      "       [ -1.01738656e-02],\n",
      "       [ -4.45722523e-03],\n",
      "       [ -1.04226250e-02],\n",
      "       [ -4.32559046e-03],\n",
      "       [ -8.15834845e-03],\n",
      "       [ -1.21031995e-02],\n",
      "       [ -1.28501679e-02],\n",
      "       [ -1.79518738e-03],\n",
      "       [ -1.41114061e-02],\n",
      "       [ -7.22767253e-03],\n",
      "       [ -1.48471140e-02],\n",
      "       [ -7.24402619e-03],\n",
      "       [ -1.13177400e-02],\n",
      "       [ -1.30251496e-02],\n",
      "       [ -4.05689654e-03],\n",
      "       [ -5.17098952e-03],\n",
      "       [ -1.68717407e-02],\n",
      "       [ -1.05995275e-02],\n",
      "       [ -1.41296950e-02],\n",
      "       [ -8.16150004e-04],\n",
      "       [ -1.57727891e-03],\n",
      "       [ -3.74800125e-04],\n",
      "       [ -6.31034761e-04],\n",
      "       [  1.35327773e-04],\n",
      "       [  4.16733209e-03],\n",
      "       [ -1.58348856e-03],\n",
      "       [  6.82353353e-04],\n",
      "       [ -8.04636893e-04],\n",
      "       [ -7.25707494e-03],\n",
      "       [  2.53482914e-03],\n",
      "       [ -8.03244498e-03],\n",
      "       [  7.54853089e-04],\n",
      "       [ -7.54719029e-03],\n",
      "       [ -8.47704020e-04],\n",
      "       [ -3.56380808e-03],\n",
      "       [  7.90711555e-05],\n",
      "       [ -9.22190425e-03],\n",
      "       [ -2.47276274e-03],\n",
      "       [ -4.14680046e-03],\n",
      "       [  2.10676361e-03],\n",
      "       [ -2.89302110e-03],\n",
      "       [ -8.89707240e-04],\n",
      "       [ -6.06425265e-03],\n",
      "       [  8.69055007e-04],\n",
      "       [ -7.62928990e-03],\n",
      "       [ -2.51060903e-03],\n",
      "       [ -7.95940581e-03],\n",
      "       [ -2.36066425e-03],\n",
      "       [ -8.16734624e-03],\n",
      "       [  3.67926013e-03],\n",
      "       [ -1.31936135e-02],\n",
      "       [ -2.63993897e-03],\n",
      "       [ -1.42991743e-02],\n",
      "       [ -1.04207226e-02],\n",
      "       [ -1.25657230e-02],\n",
      "       [ -3.50513865e-03],\n",
      "       [ -1.52842672e-02],\n",
      "       [ -1.38766623e-02],\n",
      "       [ -1.48559747e-02],\n",
      "       [  3.39552044e-03],\n",
      "       [ -1.27673980e-02],\n",
      "       [ -9.06064241e-03],\n",
      "       [ -1.52620958e-02],\n",
      "       [ -5.99926526e-03],\n",
      "       [ -1.42899790e-02],\n",
      "       [ -1.46568915e-02],\n",
      "       [ -1.58248016e-02],\n",
      "       [ -1.69207339e-02],\n",
      "       [ -1.82151087e-02],\n",
      "       [ -6.41987555e-04],\n",
      "       [ -1.50453300e-02],\n",
      "       [ -9.20283368e-03],\n",
      "       [ -1.50592535e-02],\n",
      "       [ -1.43409862e-02],\n",
      "       [ -1.79508204e-02],\n",
      "       [ -1.64024993e-02],\n",
      "       [ -1.74190933e-02],\n",
      "       [ -1.59682872e-02],\n",
      "       [  5.73904129e-03],\n",
      "       [ -1.57348207e-02],\n",
      "       [ -1.38905382e-02],\n",
      "       [ -1.05939806e-02],\n",
      "       [ -1.05040639e-02],\n",
      "       [ -1.31517622e-02],\n",
      "       [ -1.45112793e-02],\n",
      "       [ -1.60208577e-02],\n",
      "       [ -1.77907251e-02],\n",
      "       [ -1.12233783e-02],\n",
      "       [ -1.56068178e-02],\n",
      "       [ -1.78525999e-02],\n",
      "       [ -1.63238042e-02],\n",
      "       [ -1.55624836e-02],\n",
      "       [ -1.73356116e-02],\n",
      "       [ -1.25087638e-03],\n",
      "       [ -1.78445844e-02],\n",
      "       [ -1.60056705e-02],\n",
      "       [ -1.51275949e-02],\n",
      "       [ -1.76969686e-02],\n",
      "       [ -1.79845557e-02],\n",
      "       [ -1.59023354e-02],\n",
      "       [ -1.78703314e-02],\n",
      "       [ -1.77735560e-02],\n",
      "       [ -1.70046497e-02],\n",
      "       [ -1.63440230e-02],\n",
      "       [ -1.75719796e-02],\n",
      "       [ -7.29072834e-03],\n",
      "       [ -1.82244437e-02],\n",
      "       [ -1.02548189e-02],\n",
      "       [ -1.63031743e-02],\n",
      "       [ -1.74393912e-02],\n",
      "       [ -1.79930394e-02],\n",
      "       [ -1.74123644e-02],\n",
      "       [ -1.73460681e-02],\n",
      "       [ -1.74530165e-02],\n",
      "       [ -1.50201947e-02],\n",
      "       [ -1.97756255e-02],\n",
      "       [ -1.72435781e-02],\n",
      "       [ -1.81966432e-02],\n",
      "       [ -1.47644104e-02],\n",
      "       [ -1.76226811e-02],\n",
      "       [ -1.40725899e-02],\n",
      "       [ -1.90194884e-02],\n",
      "       [ -1.62516191e-02],\n",
      "       [ -1.87293696e-02],\n",
      "       [ -1.60901775e-02],\n",
      "       [ -1.69848118e-02],\n",
      "       [ -1.70856468e-02],\n",
      "       [ -1.75863601e-02],\n",
      "       [ -1.63541139e-02],\n",
      "       [ -1.91644851e-02],\n",
      "       [ -1.92056079e-02],\n",
      "       [ -1.76373639e-02],\n",
      "       [ -1.78768059e-02],\n",
      "       [ -1.79176934e-02],\n",
      "       [ -1.82906286e-02]]))\n",
      "('Intercept: \\n', array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.14048071,  0.        ,\n",
      "        0.        ,  0.        , -0.04519227,  0.        ,  0.        ,\n",
      "        0.        , -1.36544055,  0.        , -1.05760222,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -1.30498156,  0.        ,\n",
      "       -0.494467  ,  0.        ,  0.        ,  0.        , -0.48014839,\n",
      "        0.        , -2.58846101,  0.        , -2.13587713, -1.1004601 ,\n",
      "        0.        ,  0.        , -2.2850379 ,  0.        , -0.68998483,\n",
      "        0.        , -1.72240043, -0.52750567,  0.        , -2.72048402,\n",
      "       -2.15758352,  0.        , -0.51407861,  0.        , -2.14653327,\n",
      "       -3.66984676, -3.96819014, -3.97703169, -4.04346499, -5.01604245,\n",
      "       -3.25797296, -4.53283345, -4.14939755, -1.82989427, -4.72353165,\n",
      "       -1.75930967, -4.18939743, -2.23480785, -4.49953625, -3.20184323,\n",
      "       -4.68934524, -1.24973871, -3.96246474, -3.52037291, -4.43725321,\n",
      "       -3.5832764 , -4.61925307, -2.30938457, -4.74136176, -1.93623319,\n",
      "       -3.79017001, -1.95976838, -3.94769401, -1.6964884 , -5.91410486,\n",
      "        0.        , -3.95125223,  0.        , -0.73251178, -0.01396585,\n",
      "       -3.23453317,  0.        ,  0.        ,  0.        , -5.8058275 ,\n",
      "        0.        , -1.6949932 ,  0.        , -2.65863186,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        , -4.8453745 ,\n",
      "        0.        , -1.51677839,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -7.49481797,  0.        ,\n",
      "        0.        , -1.43692874, -1.18883135, -0.38464132,  0.        ,\n",
      "        0.        ,  0.        , -0.57392325,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -4.67138272,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       -2.33735344,  0.        , -1.57988718,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       -0.02023907,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]))\n",
      "The mean square error is 56933373639.7\n",
      "('Coefficients: \\n', array([[-0.01502506],\n",
      "       [-0.01632244],\n",
      "       [-0.01541933],\n",
      "       [-0.01522975],\n",
      "       [-0.01903933],\n",
      "       [-0.01244377],\n",
      "       [-0.01526459],\n",
      "       [-0.01440109],\n",
      "       [-0.0142305 ],\n",
      "       [-0.01260853],\n",
      "       [-0.0130348 ],\n",
      "       [-0.01315419],\n",
      "       [-0.00903721],\n",
      "       [-0.00745889],\n",
      "       [-0.00956858],\n",
      "       [-0.00999107],\n",
      "       [-0.01218578],\n",
      "       [-0.00670624],\n",
      "       [-0.01468701],\n",
      "       [-0.01321657],\n",
      "       [-0.01423086],\n",
      "       [-0.00761425],\n",
      "       [-0.00582694],\n",
      "       [-0.00828511],\n",
      "       [-0.01280056],\n",
      "       [-0.01119801],\n",
      "       [-0.01305163],\n",
      "       [-0.00949722],\n",
      "       [-0.01199591],\n",
      "       [-0.00455869],\n",
      "       [-0.01227648],\n",
      "       [-0.01087483],\n",
      "       [-0.01199026],\n",
      "       [-0.0048405 ],\n",
      "       [-0.01008407],\n",
      "       [-0.00549505],\n",
      "       [-0.01033234],\n",
      "       [-0.004612  ],\n",
      "       [-0.00749588],\n",
      "       [-0.01242692],\n",
      "       [-0.01389104],\n",
      "       [-0.00145655],\n",
      "       [-0.01368743],\n",
      "       [-0.00897875],\n",
      "       [-0.01491909],\n",
      "       [-0.0091197 ],\n",
      "       [-0.00584038],\n",
      "       [-0.01337776],\n",
      "       [-0.00474315],\n",
      "       [-0.00563114],\n",
      "       [-0.01468156],\n",
      "       [-0.01101908],\n",
      "       [-0.01475202],\n",
      "       [-0.00028599],\n",
      "       [-0.00182216],\n",
      "       [-0.00123497],\n",
      "       [-0.00078979],\n",
      "       [ 0.00030842],\n",
      "       [ 0.00409692],\n",
      "       [-0.00019474],\n",
      "       [ 0.00085738],\n",
      "       [ 0.00084865],\n",
      "       [-0.0055181 ],\n",
      "       [ 0.00217642],\n",
      "       [-0.00867446],\n",
      "       [ 0.00025264],\n",
      "       [-0.00382837],\n",
      "       [-0.00453744],\n",
      "       [-0.00511209],\n",
      "       [ 0.00024123],\n",
      "       [-0.00995038],\n",
      "       [ 0.00027672],\n",
      "       [-0.0041456 ],\n",
      "       [ 0.00099264],\n",
      "       [-0.00533307],\n",
      "       [-0.00060134],\n",
      "       [-0.006049  ],\n",
      "       [ 0.00122624],\n",
      "       [-0.00642218],\n",
      "       [-0.00156659],\n",
      "       [-0.00829137],\n",
      "       [-0.00132848],\n",
      "       [-0.00487242],\n",
      "       [ 0.00508374],\n",
      "       [-0.01348294],\n",
      "       [-0.00287531],\n",
      "       [-0.01753076],\n",
      "       [-0.00693153],\n",
      "       [-0.00871792],\n",
      "       [-0.00271435],\n",
      "       [-0.01524786],\n",
      "       [-0.01004937],\n",
      "       [-0.00680663],\n",
      "       [ 0.00212895],\n",
      "       [-0.01237188],\n",
      "       [-0.00616688],\n",
      "       [-0.01614905],\n",
      "       [-0.00949409],\n",
      "       [-0.01434725],\n",
      "       [-0.01270708],\n",
      "       [-0.01578577],\n",
      "       [-0.01632114],\n",
      "       [-0.01816288],\n",
      "       [-0.00337395],\n",
      "       [-0.01500991],\n",
      "       [-0.007006  ],\n",
      "       [-0.01510618],\n",
      "       [-0.01001611],\n",
      "       [-0.01790021],\n",
      "       [-0.01636061],\n",
      "       [-0.01800199],\n",
      "       [ 0.00547259],\n",
      "       [-0.01785093],\n",
      "       [-0.01385993],\n",
      "       [-0.01461251],\n",
      "       [-0.01277426],\n",
      "       [-0.01478451],\n",
      "       [-0.01383081],\n",
      "       [-0.01795061],\n",
      "       [-0.01612969],\n",
      "       [-0.01089967],\n",
      "       [-0.01556884],\n",
      "       [-0.01816287],\n",
      "       [-0.01780253],\n",
      "       [-0.01628227],\n",
      "       [-0.01552461],\n",
      "       [-0.01772399],\n",
      "       [-0.00060933],\n",
      "       [-0.01596575],\n",
      "       [-0.01382548],\n",
      "       [-0.01764787],\n",
      "       [-0.0159175 ],\n",
      "       [-0.01586293],\n",
      "       [-0.017724  ],\n",
      "       [-0.01695952],\n",
      "       [-0.0163025 ],\n",
      "       [-0.01752361],\n",
      "       [-0.0136834 ],\n",
      "       [-0.01046678],\n",
      "       [-0.01757402],\n",
      "       [-0.01825891],\n",
      "       [-0.01767804],\n",
      "       [-0.0176033 ],\n",
      "       [-0.01798475],\n",
      "       [-0.01736485],\n",
      "       [-0.01729902],\n",
      "       [-0.01740526],\n",
      "       [-0.01604982],\n",
      "       [-0.01971255],\n",
      "       [-0.01719711],\n",
      "       [-0.01563659],\n",
      "       [-0.01757402],\n",
      "       [-0.01509442],\n",
      "       [-0.01896188],\n",
      "       [-0.01519283],\n",
      "       [-0.01604984],\n",
      "       [-0.01693979],\n",
      "       [-0.01873095],\n",
      "       [-0.01753792],\n",
      "       [-0.0146511 ],\n",
      "       [-0.01758862],\n",
      "       [-0.01798473],\n",
      "       [-0.01786726],\n",
      "       [-0.01823787]]))\n",
      "('Intercept: \\n', array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , -0.4034258 , -0.03590067,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , -1.45391389, -1.27277149,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , -0.64870847,  0.        , -0.54849952,\n",
      "        0.        ,  0.        ,  0.        , -0.5598872 ,  0.        ,\n",
      "       -2.03619827, -0.02177405, -2.07286903, -1.206743  ,  0.        ,\n",
      "        0.        , -2.47712674,  0.        ,  0.        ,  0.        ,\n",
      "       -1.20285062, -2.39675481,  0.        , -2.38344438, -2.00729628,\n",
      "        0.        , -0.39386828,  0.        , -2.38836069, -3.66294359,\n",
      "       -3.51877218, -3.9686003 , -4.01004865, -5.04414378, -4.03745384,\n",
      "       -4.61673118, -4.96195421, -2.4432635 , -4.55938757, -1.47595404,\n",
      "       -3.95167532, -3.92406113, -2.94510763, -2.43159042, -4.76602902,\n",
      "       -0.84542347, -5.29775928, -3.50521406, -3.87017883, -2.42959756,\n",
      "       -4.74285785, -2.19874709, -4.93313467, -2.39031731, -4.19167892,\n",
      "       -1.81241322, -4.30666476, -3.0946235 , -6.57142747,  0.        ,\n",
      "       -3.71646922,  0.        , -2.02653257, -1.44994446, -3.59767991,\n",
      "        0.        , -1.14239887, -2.78171358, -5.19540248, -0.08549017,\n",
      "       -2.74807185,  0.        , -1.19742816,  0.        , -0.03529059,\n",
      "        0.        ,  0.        ,  0.        , -3.71387397,  0.        ,\n",
      "       -2.20390238,  0.        , -1.15653579,  0.        ,  0.        ,\n",
      "        0.        , -7.34924875,  0.        ,  0.        ,  0.        ,\n",
      "       -0.23550506,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       -0.68727818,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , -4.9755036 ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -1.47854377,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ]))\n",
      "The mean square error is 65740389021.5\n",
      "('Coefficients: \\n', array([[-0.01641794],\n",
      "       [-0.0164367 ],\n",
      "       [-0.01496551],\n",
      "       [-0.01614486],\n",
      "       [-0.01917286],\n",
      "       [-0.01255773],\n",
      "       [-0.0153673 ],\n",
      "       [-0.01392516],\n",
      "       [-0.01426878],\n",
      "       [-0.01284961],\n",
      "       [-0.01305348],\n",
      "       [-0.01392328],\n",
      "       [-0.00956109],\n",
      "       [-0.00751344],\n",
      "       [-0.00948158],\n",
      "       [-0.00997284],\n",
      "       [-0.01318166],\n",
      "       [-0.00652119],\n",
      "       [-0.0150014 ],\n",
      "       [-0.01278283],\n",
      "       [-0.01433282],\n",
      "       [-0.00691683],\n",
      "       [-0.00568272],\n",
      "       [-0.00842366],\n",
      "       [-0.01292574],\n",
      "       [-0.01111619],\n",
      "       [-0.01345003],\n",
      "       [-0.00848805],\n",
      "       [-0.01229323],\n",
      "       [-0.00498852],\n",
      "       [-0.01262562],\n",
      "       [-0.01125024],\n",
      "       [-0.01275922],\n",
      "       [-0.00573797],\n",
      "       [-0.01010312],\n",
      "       [-0.00551507],\n",
      "       [-0.00976003],\n",
      "       [-0.00460062],\n",
      "       [-0.00754041],\n",
      "       [-0.01194656],\n",
      "       [-0.01342772],\n",
      "       [-0.00118881],\n",
      "       [-0.01419818],\n",
      "       [-0.00721877],\n",
      "       [-0.01431651],\n",
      "       [-0.00724262],\n",
      "       [-0.00721667],\n",
      "       [-0.01281706],\n",
      "       [-0.0040154 ],\n",
      "       [-0.00511347],\n",
      "       [-0.01478602],\n",
      "       [-0.01114389],\n",
      "       [-0.01613903],\n",
      "       [ 0.00035427],\n",
      "       [-0.00206584],\n",
      "       [ 0.00053485],\n",
      "       [-0.00017131],\n",
      "       [-0.00080478],\n",
      "       [ 0.00317827],\n",
      "       [-0.00156402],\n",
      "       [ 0.00183422],\n",
      "       [ 0.0010082 ],\n",
      "       [-0.00599   ],\n",
      "       [ 0.00297867],\n",
      "       [-0.01066306],\n",
      "       [ 0.00027185],\n",
      "       [-0.00521587],\n",
      "       [ 0.00016027],\n",
      "       [-0.00279393],\n",
      "       [ 0.00112235],\n",
      "       [-0.00896998],\n",
      "       [-0.0001272 ],\n",
      "       [-0.00913542],\n",
      "       [ 0.0016544 ],\n",
      "       [-0.00343167],\n",
      "       [ 0.00073265],\n",
      "       [-0.00738495],\n",
      "       [-0.0002849 ],\n",
      "       [-0.00568875],\n",
      "       [-0.00205582],\n",
      "       [-0.00458116],\n",
      "       [-0.00321723],\n",
      "       [-0.00422045],\n",
      "       [ 0.00268986],\n",
      "       [-0.01444414],\n",
      "       [-0.00315632],\n",
      "       [-0.01513657],\n",
      "       [-0.00478768],\n",
      "       [-0.00755442],\n",
      "       [-0.00269797],\n",
      "       [-0.01535556],\n",
      "       [-0.00641185],\n",
      "       [-0.00970977],\n",
      "       [ 0.0028207 ],\n",
      "       [-0.01207795],\n",
      "       [-0.00398834],\n",
      "       [-0.01400089],\n",
      "       [-0.01012329],\n",
      "       [-0.01308268],\n",
      "       [-0.01273346],\n",
      "       [-0.0158967 ],\n",
      "       [-0.01559046],\n",
      "       [-0.01630748],\n",
      "       [-0.00171764],\n",
      "       [-0.01440251],\n",
      "       [-0.01195464],\n",
      "       [-0.01527175],\n",
      "       [-0.01430031],\n",
      "       [-0.01529208],\n",
      "       [-0.01647502],\n",
      "       [-0.01604036],\n",
      "       [ 0.00545049],\n",
      "       [-0.0158066 ],\n",
      "       [-0.01463456],\n",
      "       [-0.01027906],\n",
      "       [-0.00822505],\n",
      "       [-0.01488954],\n",
      "       [-0.01590301],\n",
      "       [-0.01609299],\n",
      "       [-0.01624266],\n",
      "       [-0.01304917],\n",
      "       [-0.01487344],\n",
      "       [-0.01630744],\n",
      "       [-0.01792679],\n",
      "       [-0.01823452],\n",
      "       [-0.01563404],\n",
      "       [-0.01586953],\n",
      "       [-0.00190338],\n",
      "       [-0.01804198],\n",
      "       [-0.01392527],\n",
      "       [-0.017771  ],\n",
      "       [-0.01602921],\n",
      "       [-0.01597433],\n",
      "       [-0.01794454],\n",
      "       [-0.01784767],\n",
      "       [-0.01707793],\n",
      "       [-0.01818226],\n",
      "       [-0.01764587],\n",
      "       [-0.00698735],\n",
      "       [-0.01829904],\n",
      "       [-0.00994972],\n",
      "       [-0.01637561],\n",
      "       [-0.01780133],\n",
      "       [-0.01751314],\n",
      "       [-0.01772611],\n",
      "       [-0.01811024],\n",
      "       [-0.01806737],\n",
      "       [-0.01748609],\n",
      "       [-0.01741972],\n",
      "       [-0.01752678],\n",
      "       [-0.01644411],\n",
      "       [-0.01985163],\n",
      "       [-0.01731712],\n",
      "       [-0.01827118],\n",
      "       [-0.01483491],\n",
      "       [-0.01769663],\n",
      "       [-0.01452164],\n",
      "       [-0.0190947 ],\n",
      "       [-0.01632415],\n",
      "       [-0.01880443],\n",
      "       [-0.0161623 ],\n",
      "       [-0.01715902],\n",
      "       [-0.01766026],\n",
      "       [-0.01475539],\n",
      "       [-0.01924002],\n",
      "       [-0.01928111],\n",
      "       [-0.01827118],\n",
      "       [-0.01610823]]))\n",
      "('Intercept: \\n', array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , -0.19511128,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , -1.90024661, -1.31955843,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , -1.0611327 ,  0.        , -0.32490789,\n",
      "        0.        ,  0.        ,  0.        , -0.21722759,  0.        ,\n",
      "       -2.06067976, -0.30518782, -1.92661499, -1.17037361,  0.        ,\n",
      "        0.        , -2.66486425,  0.        , -0.72765365,  0.        ,\n",
      "       -1.86397208, -1.75141643,  0.        , -2.57990157, -2.03215537,\n",
      "        0.        , -0.39048556,  0.        , -2.68025187, -3.48436513,\n",
      "       -4.4841607 , -4.22540795, -3.59014997, -4.61709878, -3.50154634,\n",
      "       -4.97530972, -5.01772329, -2.3096862 , -4.93527519, -0.82752049,\n",
      "       -4.05209225, -3.20537386, -4.93508332, -3.47002586, -5.10403006,\n",
      "       -1.31113641, -5.24030505, -1.58173065, -4.15360286, -3.38113639,\n",
      "       -5.39374184, -1.74765388, -4.21784597, -2.7606408 , -4.19236932,\n",
      "       -3.41385528, -3.58213065, -3.36341736, -5.46186644,  0.        ,\n",
      "       -3.72923314,  0.        , -3.03652418, -1.92219452, -3.55498397,\n",
      "        0.        , -2.67934155, -1.68504122, -5.47180398,  0.        ,\n",
      "       -3.68881796,  0.        , -1.16077025, -0.29005913,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -4.3492341 ,  0.        ,\n",
      "       -0.38927376,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , -7.33303595,  0.        ,  0.        , -1.60222225,\n",
      "       -2.07376624,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , -4.3777906 ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -2.50323466,  0.        ,\n",
      "       -1.74145944,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ]))\n",
      "The mean square error is 58175729946.5\n",
      "('Coefficients: \\n', array([[ -1.82640250e-02],\n",
      "       [ -1.49217096e-02],\n",
      "       [ -1.64208332e-02],\n",
      "       [ -1.27671445e-02],\n",
      "       [ -1.53214079e-02],\n",
      "       [ -1.40465638e-02],\n",
      "       [ -1.38289354e-02],\n",
      "       [ -1.27976786e-02],\n",
      "       [ -1.28167883e-02],\n",
      "       [ -1.24648532e-02],\n",
      "       [ -1.00049493e-02],\n",
      "       [ -7.64399173e-03],\n",
      "       [ -9.53932660e-03],\n",
      "       [ -9.99574843e-03],\n",
      "       [ -1.22466565e-02],\n",
      "       [ -6.29641933e-03],\n",
      "       [ -1.44752497e-02],\n",
      "       [ -1.27826926e-02],\n",
      "       [ -1.47261378e-02],\n",
      "       [ -6.62002690e-03],\n",
      "       [ -1.84390304e-02],\n",
      "       [ -5.33398606e-03],\n",
      "       [ -8.22560246e-03],\n",
      "       [ -1.37642166e-02],\n",
      "       [ -1.14180420e-02],\n",
      "       [ -1.27981096e-02],\n",
      "       [ -1.13623363e-02],\n",
      "       [ -1.21850141e-02],\n",
      "       [ -4.27122111e-03],\n",
      "       [ -1.31007243e-02],\n",
      "       [ -1.12350339e-02],\n",
      "       [ -1.18377280e-02],\n",
      "       [ -5.56370337e-03],\n",
      "       [ -9.86917289e-03],\n",
      "       [ -6.02436297e-03],\n",
      "       [ -9.04320509e-03],\n",
      "       [ -7.51152915e-03],\n",
      "       [ -8.51127317e-03],\n",
      "       [ -1.22375824e-02],\n",
      "       [ -1.40190322e-02],\n",
      "       [ -2.54104404e-03],\n",
      "       [ -1.33819103e-02],\n",
      "       [ -7.87592385e-03],\n",
      "       [ -1.42760715e-02],\n",
      "       [ -6.78564339e-03],\n",
      "       [ -5.89922835e-03],\n",
      "       [ -1.30249700e-02],\n",
      "       [ -4.43784878e-03],\n",
      "       [ -5.44518899e-03],\n",
      "       [ -1.56180322e-02],\n",
      "       [ -1.22555485e-02],\n",
      "       [ -1.47979041e-02],\n",
      "       [  2.55283666e-05],\n",
      "       [ -5.22890578e-04],\n",
      "       [ -1.30523985e-03],\n",
      "       [ -7.87013174e-04],\n",
      "       [  4.64966827e-04],\n",
      "       [  4.40245876e-03],\n",
      "       [ -1.54194484e-03],\n",
      "       [  7.80277542e-04],\n",
      "       [  2.10751942e-03],\n",
      "       [ -5.43933125e-03],\n",
      "       [  3.20342723e-03],\n",
      "       [ -1.23545755e-02],\n",
      "       [ -1.13282746e-03],\n",
      "       [ -9.27690745e-03],\n",
      "       [ -9.52073192e-04],\n",
      "       [ -3.24766853e-03],\n",
      "       [  1.44634732e-04],\n",
      "       [ -8.65000864e-03],\n",
      "       [ -1.78667057e-03],\n",
      "       [ -5.09986248e-03],\n",
      "       [  1.89970375e-03],\n",
      "       [ -5.67185389e-03],\n",
      "       [ -2.44934127e-03],\n",
      "       [ -5.86284514e-03],\n",
      "       [  5.17537267e-04],\n",
      "       [ -6.81560222e-03],\n",
      "       [ -1.88749566e-03],\n",
      "       [ -5.34167579e-03],\n",
      "       [ -3.56965148e-03],\n",
      "       [ -9.19926736e-03],\n",
      "       [  4.39701052e-03],\n",
      "       [ -1.32267469e-02],\n",
      "       [ -3.29783319e-03],\n",
      "       [ -1.50918695e-02],\n",
      "       [ -5.76743814e-03],\n",
      "       [ -1.13763964e-02],\n",
      "       [ -3.32189147e-03],\n",
      "       [ -1.65455670e-02],\n",
      "       [ -1.00164401e-02],\n",
      "       [ -7.04373554e-03],\n",
      "       [  3.40307739e-03],\n",
      "       [ -1.25146461e-02],\n",
      "       [ -6.81586620e-03],\n",
      "       [ -1.34924473e-02],\n",
      "       [ -7.33290531e-03],\n",
      "       [ -1.43579481e-02],\n",
      "       [ -1.24429177e-02],\n",
      "       [ -1.74699207e-02],\n",
      "       [ -1.55433200e-02],\n",
      "       [ -1.82268304e-02],\n",
      "       [ -2.79837400e-04],\n",
      "       [ -1.49490368e-02],\n",
      "       [ -8.14668936e-03],\n",
      "       [ -1.45386857e-02],\n",
      "       [ -1.34222638e-02],\n",
      "       [ -1.60696805e-02],\n",
      "       [ -1.64229882e-02],\n",
      "       [ -1.74347965e-02],\n",
      "       [ -1.59907371e-02],\n",
      "       [  6.26637039e-03],\n",
      "       [ -1.57582820e-02],\n",
      "       [ -1.45925311e-02],\n",
      "       [ -1.46381856e-02],\n",
      "       [ -1.07333905e-02],\n",
      "       [ -1.74214340e-02],\n",
      "       [ -1.43100790e-02],\n",
      "       [ -1.60430818e-02],\n",
      "       [ -1.80831565e-02],\n",
      "       [ -8.17493479e-03],\n",
      "       [ -1.59503977e-02],\n",
      "       [ -1.62563611e-02],\n",
      "       [ -1.78661412e-02],\n",
      "       [ -1.63445885e-02],\n",
      "       [ -1.55866769e-02],\n",
      "       [  1.69239492e-03],\n",
      "       [ -1.78581649e-02],\n",
      "       [ -1.79806229e-02],\n",
      "       [ -1.44722395e-02],\n",
      "       [ -1.77112958e-02],\n",
      "       [ -1.59796713e-02],\n",
      "       [ -1.76373862e-02],\n",
      "       [ -1.78837842e-02],\n",
      "       [ -1.77875062e-02],\n",
      "       [ -1.63648991e-02],\n",
      "       [ -1.75869342e-02],\n",
      "       [ -1.42733769e-02],\n",
      "       [ -1.82360878e-02],\n",
      "       [ -1.46638902e-02],\n",
      "       [ -1.76373862e-02],\n",
      "       [ -1.63241532e-02],\n",
      "       [ -1.77415010e-02],\n",
      "       [ -1.74549963e-02],\n",
      "       [ -1.80484821e-02],\n",
      "       [ -1.80058574e-02],\n",
      "       [ -1.73621411e-02],\n",
      "       [ -1.74685631e-02],\n",
      "       [ -1.50466086e-02],\n",
      "       [ -1.97785364e-02],\n",
      "       [ -1.72601506e-02],\n",
      "       [ -1.82083476e-02],\n",
      "       [ -1.58822782e-02],\n",
      "       [ -1.76373819e-02],\n",
      "       [ -1.58822767e-02],\n",
      "       [ -1.52546977e-02],\n",
      "       [ -1.87382835e-02],\n",
      "       [ -1.61120972e-02],\n",
      "       [ -1.70025783e-02],\n",
      "       [ -1.71029874e-02],\n",
      "       [ -1.76012450e-02],\n",
      "       [ -1.47126912e-02],\n",
      "       [ -1.91710615e-02],\n",
      "       [ -1.92117585e-02],\n",
      "       [ -1.76519406e-02],\n",
      "       [ -1.78902311e-02],\n",
      "       [ -1.60581460e-02]]))\n",
      "('Intercept: \\n', array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       -0.22963656,  0.        ,  0.        ,  0.        , -1.74626435,\n",
      "        0.        , -1.55051903,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , -0.0278703 ,  0.        , -0.71168823,  0.        ,\n",
      "        0.        ,  0.        , -0.25266639,  0.        , -1.86387705,\n",
      "       -0.56353586, -0.75042307, -0.72434793,  0.        ,  0.        ,\n",
      "       -1.92117937,  0.        , -0.4874703 ,  0.        , -2.05845481,\n",
      "       -2.34933945,  0.        , -2.45927439, -1.89837281,  0.        ,\n",
      "        0.        ,  0.        , -2.55351023, -4.10043415, -3.45916056,\n",
      "       -3.92313268, -4.16383696, -5.19939506, -3.38359676, -4.44715799,\n",
      "       -5.57446898, -2.66959258, -5.02254547, -0.1090774 , -3.38165532,\n",
      "       -1.61564909, -4.43285271, -3.29667683, -4.71095186, -1.42870433,\n",
      "       -4.2086138 , -3.01728112, -4.30905086, -2.34142197, -3.94888909,\n",
      "       -2.37413652, -4.44863874, -2.24623506, -4.11121432, -3.06458905,\n",
      "       -3.53560128, -1.19483784, -6.19015046,  0.        , -3.5945358 ,\n",
      "        0.        , -2.51042869, -0.51566494, -3.43324625,  0.        ,\n",
      "       -1.29071103, -2.69942192, -5.71957469,  0.        , -2.69403658,\n",
      "        0.        , -2.08529067,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        , -4.99290491,  0.        , -1.81389019,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , -7.74384514,  0.        ,  0.        ,  0.        ,\n",
      "       -1.10627307,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       -1.80160766,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , -6.0874819 ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ]))\n",
      "The mean square error is 51778371161.5\n",
      "('Coefficients: \\n', array([[ -1.51059268e-02],\n",
      "       [ -1.64119109e-02],\n",
      "       [ -1.55026887e-02],\n",
      "       [ -1.45305529e-02],\n",
      "       [ -1.91505089e-02],\n",
      "       [ -1.27700246e-02],\n",
      "       [ -1.53419175e-02],\n",
      "       [ -1.39904399e-02],\n",
      "       [ -1.38410377e-02],\n",
      "       [ -1.30959535e-02],\n",
      "       [ -1.25162679e-02],\n",
      "       [ -1.27719132e-02],\n",
      "       [ -9.83206175e-03],\n",
      "       [ -7.74579329e-03],\n",
      "       [ -9.51196837e-03],\n",
      "       [ -9.87339901e-03],\n",
      "       [ -1.26257513e-02],\n",
      "       [ -6.73387903e-03],\n",
      "       [ -1.44908947e-02],\n",
      "       [ -1.28200243e-02],\n",
      "       [ -1.37477172e-02],\n",
      "       [ -7.98477514e-03],\n",
      "       [ -1.84800235e-02],\n",
      "       [ -5.07777814e-03],\n",
      "       [ -8.45535229e-03],\n",
      "       [ -1.31931753e-02],\n",
      "       [ -1.16656652e-02],\n",
      "       [ -1.34089090e-02],\n",
      "       [ -8.10120217e-03],\n",
      "       [ -1.20593348e-02],\n",
      "       [ -4.72595372e-03],\n",
      "       [ -1.23240427e-02],\n",
      "       [ -1.08015473e-02],\n",
      "       [ -1.17481261e-02],\n",
      "       [ -5.35633773e-03],\n",
      "       [ -9.92044038e-03],\n",
      "       [ -5.93953391e-03],\n",
      "       [ -1.04272995e-02],\n",
      "       [ -4.83343795e-03],\n",
      "       [ -8.52039828e-03],\n",
      "       [ -1.26734187e-02],\n",
      "       [ -1.31364814e-02],\n",
      "       [ -2.49279060e-03],\n",
      "       [ -1.38603930e-02],\n",
      "       [ -7.87383957e-03],\n",
      "       [ -1.46421257e-02],\n",
      "       [ -8.94638689e-03],\n",
      "       [ -7.91378455e-03],\n",
      "       [ -1.33903748e-02],\n",
      "       [ -4.59029844e-03],\n",
      "       [ -5.92608442e-03],\n",
      "       [ -1.47603095e-02],\n",
      "       [ -1.05298992e-02],\n",
      "       [ -1.44961988e-02],\n",
      "       [  1.13694579e-04],\n",
      "       [ -2.69727634e-03],\n",
      "       [ -5.51707619e-04],\n",
      "       [ -1.54221718e-03],\n",
      "       [  1.95405101e-04],\n",
      "       [  3.28246847e-03],\n",
      "       [ -1.66037739e-03],\n",
      "       [  9.47697446e-04],\n",
      "       [  1.21328702e-03],\n",
      "       [ -8.14047502e-03],\n",
      "       [  2.16899929e-03],\n",
      "       [ -9.63474360e-03],\n",
      "       [  1.14045849e-03],\n",
      "       [ -3.38921391e-03],\n",
      "       [ -1.38797105e-03],\n",
      "       [ -5.21507248e-03],\n",
      "       [  7.42213460e-04],\n",
      "       [ -1.26066166e-02],\n",
      "       [ -1.97476222e-03],\n",
      "       [ -5.46128668e-03],\n",
      "       [  1.04509108e-03],\n",
      "       [ -4.69898950e-03],\n",
      "       [ -1.75869097e-03],\n",
      "       [ -9.03032694e-03],\n",
      "       [ -8.04850168e-04],\n",
      "       [ -5.82542117e-03],\n",
      "       [ -2.94236853e-03],\n",
      "       [ -1.00295799e-02],\n",
      "       [ -5.44692077e-04],\n",
      "       [ -5.03996911e-03],\n",
      "       [  4.08995302e-03],\n",
      "       [ -1.37345490e-02],\n",
      "       [ -2.10963646e-03],\n",
      "       [ -1.49150619e-02],\n",
      "       [ -3.37182685e-03],\n",
      "       [ -1.29305019e-02],\n",
      "       [ -2.41320409e-03],\n",
      "       [ -1.53301344e-02],\n",
      "       [ -7.50596119e-03],\n",
      "       [ -1.47824251e-02],\n",
      "       [  3.16044469e-03],\n",
      "       [ -1.06896065e-02],\n",
      "       [ -9.23168192e-03],\n",
      "       [ -1.20246729e-02],\n",
      "       [ -7.35653802e-03],\n",
      "       [ -1.43729477e-02],\n",
      "       [ -1.24479898e-02],\n",
      "       [ -1.77472105e-02],\n",
      "       [ -1.55651611e-02],\n",
      "       [ -1.62826007e-02],\n",
      "       [  1.08655094e-05],\n",
      "       [ -1.43321433e-02],\n",
      "       [ -1.02715496e-02],\n",
      "       [ -1.66692009e-02],\n",
      "       [ -1.08610900e-02],\n",
      "       [ -1.52666223e-02],\n",
      "       [ -1.64502908e-02],\n",
      "       [ -1.74688083e-02],\n",
      "       [ -1.60153107e-02],\n",
      "       [  3.71809151e-03],\n",
      "       [ -1.79518895e-02],\n",
      "       [ -1.49988204e-02],\n",
      "       [ -1.47980632e-02],\n",
      "       [ -1.21477443e-02],\n",
      "       [ -1.30213427e-02],\n",
      "       [ -1.51008267e-02],\n",
      "       [ -1.60679808e-02],\n",
      "       [ -1.62178139e-02],\n",
      "       [ -1.01551203e-02],\n",
      "       [ -1.74286216e-02],\n",
      "       [ -1.62825403e-02],\n",
      "       [ -1.79031342e-02],\n",
      "       [ -1.63714854e-02],\n",
      "       [ -1.64636616e-02],\n",
      "       [ -1.73851832e-02],\n",
      "       [  9.98756939e-04],\n",
      "       [ -1.60528139e-02],\n",
      "       [ -1.44879487e-02],\n",
      "       [ -1.77472100e-02],\n",
      "       [ -1.75096493e-02],\n",
      "       [ -1.59492386e-02],\n",
      "       [ -1.79209006e-02],\n",
      "       [ -1.70535904e-02],\n",
      "       [ -1.63918301e-02],\n",
      "       [ -1.76219814e-02],\n",
      "       [ -7.82260184e-03],\n",
      "       [ -1.82756913e-02],\n",
      "       [ -1.47713432e-02],\n",
      "       [ -1.76727774e-02],\n",
      "       [ -1.63508807e-02],\n",
      "       [ -1.77776204e-02],\n",
      "       [ -1.74891440e-02],\n",
      "       [ -1.77022851e-02],\n",
      "       [ -1.80867852e-02],\n",
      "       [ -1.80437426e-02],\n",
      "       [ -1.74620374e-02],\n",
      "       [ -1.73956365e-02],\n",
      "       [ -1.50654801e-02],\n",
      "       [ -1.72929643e-02],\n",
      "       [ -1.82478301e-02],\n",
      "       [ -1.48092489e-02],\n",
      "       [ -1.42490551e-02],\n",
      "       [ -1.90721847e-02],\n",
      "       [ -1.52748127e-02],\n",
      "       [ -1.88045585e-02],\n",
      "       [ -1.70336519e-02],\n",
      "       [ -1.71347148e-02],\n",
      "       [ -1.76363904e-02],\n",
      "       [ -1.52748123e-02],\n",
      "       [ -1.92176056e-02],\n",
      "       [ -1.92587340e-02],\n",
      "       [ -1.76874867e-02],\n",
      "       [ -1.82478283e-02],\n",
      "       [ -1.80867852e-02],\n",
      "       [ -1.79273925e-02],\n",
      "       [ -1.79683458e-02],\n",
      "       [ -1.83420092e-02]]))\n",
      "('Intercept: \\n', array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02974884,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , -1.17166318,  0.        , -1.74043654,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -1.18591452,  0.        ,\n",
      "       -0.44268887,  0.        , -0.10988028,  0.        , -0.33473071,\n",
      "        0.        , -2.04412286,  0.        , -1.90775927, -0.78715776,\n",
      "        0.        ,  0.        , -2.00289596,  0.        , -0.50718353,\n",
      "        0.        , -1.16956545, -1.67978061,  0.        , -2.29322941,\n",
      "       -1.97597638,  0.        , -0.43431095,  0.        , -2.59612715,\n",
      "       -3.11053962, -3.85229261, -3.4276981 , -3.95690042, -4.60628743,\n",
      "       -3.28971768, -4.45685229, -5.23017621, -1.5841018 , -4.43552058,\n",
      "       -1.16511956, -4.59353513, -3.95360045, -4.29698507, -2.4399573 ,\n",
      "       -4.96097451, -0.01589744, -4.33041699, -2.83732496, -3.90958201,\n",
      "       -2.9411718 , -4.43406545, -1.07693871, -3.94079645, -2.53901377,\n",
      "       -3.64732481, -1.28496003, -4.90432435, -2.90853821, -6.11018271,\n",
      "        0.        , -4.09791228,  0.        , -3.50062978, -0.08738475,\n",
      "       -3.62413806,  0.        , -2.17480296,  0.        , -5.65381225,\n",
      "       -0.49904557, -1.62475779, -0.45341469, -2.24740824,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        , -5.00993057,\n",
      "        0.        , -1.18553972,  0.        , -1.04698108,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -6.64434572,  0.        ,\n",
      "        0.        ,  0.        , -0.65987438, -0.45686507,  0.        ,\n",
      "        0.        ,  0.        , -0.86164346,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        , -5.72756224,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        , -2.23780107,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,  0.        ]))\n",
      "The mean square error is 45454981084.5\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'Abhishek'\n",
    "#Only amcat scores\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neighbors\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "from scipy.sparse import hstack,csr_matrix,isspmatrix_csr\n",
    "import re\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rb\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "def splitDataset(dataframe, splitRatio):\n",
    "    msk = np.random.rand(len(dataframe)) < splitRatio\n",
    "    train,test = dataframe[msk],dataframe[~msk]\n",
    "    return (train,test)\n",
    "def extractCollegeStateFeatures(dataframe):\n",
    "    dataValues = dataframe['CollegeState'].values\n",
    "    collegeState_set = set(dataValues)\n",
    "    collegeStateDictionary = dict(enumerate(collegeState_set))\n",
    "    collegeStateList = list(collegeState_set)\n",
    "    featureList = []\n",
    "    for i in range(0,len(dataValues)):\n",
    "        featureList.append(collegeStateList.index(dataValues[i]))\n",
    "\n",
    "    return featureList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetchLabels(dataframe,salaryBar):\n",
    "    labels = []\n",
    "\n",
    "    for salaryValue in dataframe['Salary'].values:\n",
    "        if(salaryValue<=salaryBar[0]):\n",
    "            labels.append(0)\n",
    "        elif(salaryValue>salaryBar[0] and salaryValue<salaryBar[1]):\n",
    "            labels.append(1)\n",
    "        elif(salaryValue>salaryBar[1] and salaryValue<salaryBar[2]):\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(3)\n",
    "    return labels\n",
    "\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,dataframe):\n",
    "        featureSet = []\n",
    "        collegeStateFeatureList = extractCollegeStateFeatures(dataframe)\n",
    "        count = 0\n",
    "        for index,row in dataframe.iterrows():\n",
    "\n",
    "            features = {}\n",
    "            #features['12percentage'] = row['12percentage']\n",
    "            #features['10percentage'] = row['10percentage']\n",
    "\n",
    "            #features['CollegeTier'] = row['CollegeTier']\n",
    "            #features['collegeGPA'] =row['collegeGPA']\n",
    "            #features['PreUniversity'] = row[\"10percentage\"] + row[\"12percentage\"]\n",
    "            gpa = row[\"collegeGPA\"]\n",
    "            if(gpa<=10.0):\n",
    "                gpa = gpa * 10\n",
    "            #features['University'] = math.pow(gpa,(1.0/(float(row['CollegeTier']) + 1.0)))\n",
    "\n",
    "\n",
    "            domain_score = -1\n",
    "            possibledomains = 'ComputerProgramming','ElectronicsAndSemicon','ComputerScience','MechanicalEngg','ElectricalEngg','TelecomEngg','CivilEngg'\n",
    "            for domain in possibledomains:\n",
    "                if(row[domain] != '-1'):\n",
    "                    domain_score = row[domain]\n",
    "                    break\n",
    "            if domain_score != -1:\n",
    "                #features['AMCATscore'] = float(row['English'] + row['Logical'] + row['Quant'] + domain_score)/4.0\n",
    "                features['AMCATscore'] = float( row['Logical'] + row['Quant'] + domain_score)/3.0\n",
    "            else:\n",
    "                features['AMCATscore'] = float(row['Logical'] + row['Quant'])/2.0\n",
    "\n",
    "\n",
    "\n",
    "            #features['Logical'] = row['Logical']\n",
    "            #features['Quant'] = row['Quant']\n",
    "            # else:\n",
    "            #     features['Degree'] = 0\n",
    "            # if(row['Gender']=='m'):\n",
    "            #     features['Gender'] = 1\n",
    "            # else:\n",
    "            #     features['Gender'] = 0\n",
    "\n",
    "            featureSet.append(features)\n",
    "            count = count + 1\n",
    "        return featureSet\n",
    "\n",
    "def evaluate(salary_actual,salary_predicted):\n",
    "    print \"The mean square error is \"+str(mean_squared_error(salary_actual,salary_predicted))\n",
    "\n",
    "\n",
    "def main(filename):\n",
    "\n",
    "    splitRatio = 0.8\n",
    "\n",
    "    df = pd.read_excel(filename,header=0)\n",
    "\n",
    "    for i in range(0,5):\n",
    "        trainingSet, testSet = splitDataset(df, splitRatio)\n",
    "        clf = sklearn.linear_model.LogisticRegression(penalty='l1',C=0.5)\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "        # Extract the subject & body\n",
    "\n",
    "\n",
    "        # Use FeatureUnion to combine the features from subject and body\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list=[\n",
    "\n",
    "                # Pipeline for standard bag-of-words model for body\n",
    "                #('bow', Pipeline([\n",
    "                #    ('count', CountVectorizer()),\n",
    "                #    ('tfidf',TfidfTransformer()),\n",
    "                #])),\n",
    "\n",
    "                # Pipeline for pulling ad hoc features from post's body\n",
    "                ('body_stats', Pipeline([\n",
    "                    ('stats', TextStats()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "                ])),\n",
    "\n",
    "            ],\n",
    "\n",
    "            # weight components in FeatureUnion\n",
    "            #transformer_weights={\n",
    "            #    'subject': 0.8,\n",
    "            #    'body_bow': 0.5,\n",
    "            #    'body_stats': 1.0,\n",
    "            #},\n",
    "        )),\n",
    "\n",
    "        # Use a Regressor on the combined features\n",
    "        ('regressor', clf),\n",
    "    ])\n",
    "\n",
    "        model_name = \"singlelogisticregressionclassifier\"\n",
    "        #clf = sklearn.naive_bayes.MultinomialNB()\n",
    "        #train_classifiers(traincsvfile,clf)\n",
    "        #train_single_classifier(traincsvfile,pipeline,model_name)\n",
    "        predicted_labels = []\n",
    "\n",
    "\n",
    "        def f(x):\n",
    "            return float(x)\n",
    "        f = numpy.vectorize(f)\n",
    "        test_labels = f(testSet.pop('Salary'))\n",
    "        train_labels=f(trainingSet.pop('Salary'))\n",
    "        #clf.fit(trainingSet,train_labels)\n",
    "        x = pipeline.fit(trainingSet,train_labels)\n",
    "        meanvalue = numpy.mean(train_labels)\n",
    "        #predicted_labels = numpy.empty(test_labels.shape)\n",
    "        #predicted_labels.fill(meanvalue)\n",
    "        predicted_labels = pipeline.predict(testSet)\n",
    "        #predicted_labels = clf.predict(testSet)\n",
    "        #print(\"Intercept:\",clf.)\n",
    "        print('Coefficients: \\n', clf.coef_)\n",
    "        print('Intercept: \\n', clf.intercept_)\n",
    "\n",
    "\n",
    "        evaluate(test_labels,predicted_labels)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"C:\\\\Users\\\\Abhishek\\\\Downloads\\\\datachallenge_cods2016\\\\datachallenge_cods2016\\\\train.xlsx\"\n",
    "    main(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean square error is 27211836593.8\n",
      "The mean square error is 52305276705.3\n",
      "The mean square error is 34491144501.3\n",
      "The mean square error is 65731149068.3\n",
      "The mean square error is 81040167095.1\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'Abhishek'\n",
    "#Only college gpa\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neighbors\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "from scipy.sparse import hstack,csr_matrix,isspmatrix_csr\n",
    "import re\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rb\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "def splitDataset(dataframe, splitRatio):\n",
    "    msk = np.random.rand(len(dataframe)) < splitRatio\n",
    "    train,test = dataframe[msk],dataframe[~msk]\n",
    "    return (train,test)\n",
    "def extractCollegeStateFeatures(dataframe):\n",
    "    dataValues = dataframe['CollegeState'].values\n",
    "    collegeState_set = set(dataValues)\n",
    "    collegeStateDictionary = dict(enumerate(collegeState_set))\n",
    "    collegeStateList = list(collegeState_set)\n",
    "    featureList = []\n",
    "    for i in range(0,len(dataValues)):\n",
    "        featureList.append(collegeStateList.index(dataValues[i]))\n",
    "\n",
    "    return featureList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetchLabels(dataframe,salaryBar):\n",
    "    labels = []\n",
    "\n",
    "    for salaryValue in dataframe['Salary'].values:\n",
    "        if(salaryValue<=salaryBar[0]):\n",
    "            labels.append(0)\n",
    "        elif(salaryValue>salaryBar[0] and salaryValue<salaryBar[1]):\n",
    "            labels.append(1)\n",
    "        elif(salaryValue>salaryBar[1] and salaryValue<salaryBar[2]):\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(3)\n",
    "    return labels\n",
    "\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,dataframe):\n",
    "        featureSet = []\n",
    "        collegeStateFeatureList = extractCollegeStateFeatures(dataframe)\n",
    "        count = 0\n",
    "        for index,row in dataframe.iterrows():\n",
    "\n",
    "            features = {}\n",
    "            #features['12percentage'] = row['12percentage']\n",
    "            #features['10percentage'] = row['10percentage']\n",
    "\n",
    "            #features['CollegeTier'] = row['CollegeTier']\n",
    "            #features['collegeGPA'] =row['collegeGPA']\n",
    "            #features['PreUniversity'] = row[\"10percentage\"] + row[\"12percentage\"]\n",
    "            gpa = row[\"collegeGPA\"]\n",
    "            if(gpa<=10.0):\n",
    "                gpa = gpa * 10\n",
    "            features['University'] = math.pow(gpa,(1.0/(float(row['CollegeTier']) + 1.0)))\n",
    "\n",
    "\n",
    "            domain_score = -1\n",
    "            possibledomains = 'ComputerProgramming','ElectronicsAndSemicon','ComputerScience','MechanicalEngg','ElectricalEngg','TelecomEngg','CivilEngg'\n",
    "            for domain in possibledomains:\n",
    "                if(row[domain] != '-1'):\n",
    "                    domain_score = row[domain]\n",
    "                    break\n",
    "            # if domain_score != -1:\n",
    "            #     features['AMCATscore'] = float(row['English'] + row['Logical'] + row['Quant'] + domain_score)/4.0\n",
    "            #     #features['AMCATscore'] = float( row['Logical'] + row['Quant'] + domain_score)/3.0\n",
    "            # else:\n",
    "            #     features['AMCATscore'] = float(row['Logical'] + row['Quant'])/2.0\n",
    "\n",
    "\n",
    "\n",
    "            #features['Logical'] = row['Logical']\n",
    "            #features['Quant'] = row['Quant']\n",
    "            # else:\n",
    "            #     features['Degree'] = 0\n",
    "            # if(row['Gender']=='m'):\n",
    "            #     features['Gender'] = 1\n",
    "            # else:\n",
    "            #     features['Gender'] = 0\n",
    "\n",
    "            featureSet.append(features)\n",
    "            count = count + 1\n",
    "        return featureSet\n",
    "\n",
    "def evaluate(salary_actual,salary_predicted):\n",
    "    print \"The mean square error is \"+str(mean_squared_error(salary_actual,salary_predicted))\n",
    "\n",
    "\n",
    "def main(filename):\n",
    "\n",
    "    splitRatio = 0.8\n",
    "\n",
    "    df = pd.read_excel(filename,header=0)\n",
    "\n",
    "    for i in range(0,5):\n",
    "        trainingSet, testSet = splitDataset(df, splitRatio)\n",
    "        clf = sklearn.linear_model.LogisticRegression(penalty='l1',C=0.5)\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "        # Extract the subject & body\n",
    "\n",
    "\n",
    "        # Use FeatureUnion to combine the features from subject and body\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list=[\n",
    "\n",
    "                # Pipeline for standard bag-of-words model for body\n",
    "                #('bow', Pipeline([\n",
    "                #    ('count', CountVectorizer()),\n",
    "                #    ('tfidf',TfidfTransformer()),\n",
    "                #])),\n",
    "\n",
    "                # Pipeline for pulling ad hoc features from post's body\n",
    "                ('body_stats', Pipeline([\n",
    "                    ('stats', TextStats()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "                ])),\n",
    "\n",
    "            ],\n",
    "\n",
    "            # weight components in FeatureUnion\n",
    "            #transformer_weights={\n",
    "            #    'subject': 0.8,\n",
    "            #    'body_bow': 0.5,\n",
    "            #    'body_stats': 1.0,\n",
    "            #},\n",
    "        )),\n",
    "\n",
    "        # Use a Regressor on the combined features\n",
    "        ('regressor', clf),\n",
    "    ])\n",
    "\n",
    "        model_name = \"singlelogisticregressionclassifier\"\n",
    "        #clf = sklearn.naive_bayes.MultinomialNB()\n",
    "        #train_classifiers(traincsvfile,clf)\n",
    "        #train_single_classifier(traincsvfile,pipeline,model_name)\n",
    "        predicted_labels = []\n",
    "\n",
    "\n",
    "        def f(x):\n",
    "            return float(x)\n",
    "        f = numpy.vectorize(f)\n",
    "        test_labels = f(testSet.pop('Salary'))\n",
    "        train_labels=f(trainingSet.pop('Salary'))\n",
    "        #clf.fit(trainingSet,train_labels)\n",
    "        x = pipeline.fit(trainingSet,train_labels)\n",
    "        meanvalue = numpy.mean(train_labels)\n",
    "        #predicted_labels = numpy.empty(test_labels.shape)\n",
    "        #predicted_labels.fill(meanvalue)\n",
    "        predicted_labels = pipeline.predict(testSet)\n",
    "        #predicted_labels = clf.predict(testSet)\n",
    "        #print(\"Intercept:\",clf.)\n",
    "        #print('Coefficients: \\n', clf.coef_)\n",
    "        #print('Intercept: \\n', clf.intercept_)\n",
    "\n",
    "\n",
    "        evaluate(test_labels,predicted_labels)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"C:\\\\Users\\\\Abhishek\\\\Downloads\\\\datachallenge_cods2016\\\\datachallenge_cods2016\\\\train.xlsx\"\n",
    "    main(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean square error is 28323994974.9\n",
      "The mean square error is 49201250000.0\n",
      "The mean square error is 51959076433.1\n",
      "The mean square error is 40191032608.7\n",
      "The mean square error is 50847341772.2\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'Abhishek'\n",
    "#Only 10th and 12th\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neighbors\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "from scipy.sparse import hstack,csr_matrix,isspmatrix_csr\n",
    "import re\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rb\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "def splitDataset(dataframe, splitRatio):\n",
    "    msk = np.random.rand(len(dataframe)) < splitRatio\n",
    "    train,test = dataframe[msk],dataframe[~msk]\n",
    "    return (train,test)\n",
    "def extractCollegeStateFeatures(dataframe):\n",
    "    dataValues = dataframe['CollegeState'].values\n",
    "    collegeState_set = set(dataValues)\n",
    "    collegeStateDictionary = dict(enumerate(collegeState_set))\n",
    "    collegeStateList = list(collegeState_set)\n",
    "    featureList = []\n",
    "    for i in range(0,len(dataValues)):\n",
    "        featureList.append(collegeStateList.index(dataValues[i]))\n",
    "\n",
    "    return featureList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetchLabels(dataframe,salaryBar):\n",
    "    labels = []\n",
    "\n",
    "    for salaryValue in dataframe['Salary'].values:\n",
    "        if(salaryValue<=salaryBar[0]):\n",
    "            labels.append(0)\n",
    "        elif(salaryValue>salaryBar[0] and salaryValue<salaryBar[1]):\n",
    "            labels.append(1)\n",
    "        elif(salaryValue>salaryBar[1] and salaryValue<salaryBar[2]):\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(3)\n",
    "    return labels\n",
    "\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,dataframe):\n",
    "        featureSet = []\n",
    "        collegeStateFeatureList = extractCollegeStateFeatures(dataframe)\n",
    "        count = 0\n",
    "        for index,row in dataframe.iterrows():\n",
    "\n",
    "            features = {}\n",
    "            #features['12percentage'] = row['12percentage']\n",
    "            #features['10percentage'] = row['10percentage']\n",
    "\n",
    "            #features['CollegeTier'] = row['CollegeTier']\n",
    "            #features['collegeGPA'] =row['collegeGPA']\n",
    "            features['PreUniversity'] = row[\"10percentage\"] + row[\"12percentage\"]\n",
    "            gpa = row[\"collegeGPA\"]\n",
    "            if(gpa<=10.0):\n",
    "                gpa = gpa * 10\n",
    "            #features['University'] = math.pow(gpa,(1.0/(float(row['CollegeTier']) + 1.0)))\n",
    "\n",
    "\n",
    "            domain_score = -1\n",
    "            possibledomains = 'ComputerProgramming','ElectronicsAndSemicon','ComputerScience','MechanicalEngg','ElectricalEngg','TelecomEngg','CivilEngg'\n",
    "            for domain in possibledomains:\n",
    "                if(row[domain] != '-1'):\n",
    "                    domain_score = row[domain]\n",
    "                    break\n",
    "            # if domain_score != -1:\n",
    "            #     features['AMCATscore'] = float(row['English'] + row['Logical'] + row['Quant'] + domain_score)/4.0\n",
    "            #     #features['AMCATscore'] = float( row['Logical'] + row['Quant'] + domain_score)/3.0\n",
    "            # else:\n",
    "            #     features['AMCATscore'] = float(row['Logical'] + row['Quant'])/2.0\n",
    "\n",
    "\n",
    "\n",
    "            #features['Logical'] = row['Logical']\n",
    "            #features['Quant'] = row['Quant']\n",
    "            # else:\n",
    "            #     features['Degree'] = 0\n",
    "            # if(row['Gender']=='m'):\n",
    "            #     features['Gender'] = 1\n",
    "            # else:\n",
    "            #     features['Gender'] = 0\n",
    "\n",
    "            featureSet.append(features)\n",
    "            count = count + 1\n",
    "        return featureSet\n",
    "\n",
    "def evaluate(salary_actual,salary_predicted):\n",
    "    print \"The mean square error is \"+str(mean_squared_error(salary_actual,salary_predicted))\n",
    "\n",
    "\n",
    "def main(filename):\n",
    "\n",
    "    splitRatio = 0.8\n",
    "\n",
    "    df = pd.read_excel(filename,header=0)\n",
    "\n",
    "    for i in range(0,5):\n",
    "        trainingSet, testSet = splitDataset(df, splitRatio)\n",
    "        clf = sklearn.linear_model.LogisticRegression(penalty='l1',C=0.5)\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "        # Extract the subject & body\n",
    "\n",
    "\n",
    "        # Use FeatureUnion to combine the features from subject and body\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list=[\n",
    "\n",
    "                # Pipeline for standard bag-of-words model for body\n",
    "                #('bow', Pipeline([\n",
    "                #    ('count', CountVectorizer()),\n",
    "                #    ('tfidf',TfidfTransformer()),\n",
    "                #])),\n",
    "\n",
    "                # Pipeline for pulling ad hoc features from post's body\n",
    "                ('body_stats', Pipeline([\n",
    "                    ('stats', TextStats()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "                ])),\n",
    "\n",
    "            ],\n",
    "\n",
    "            # weight components in FeatureUnion\n",
    "            #transformer_weights={\n",
    "            #    'subject': 0.8,\n",
    "            #    'body_bow': 0.5,\n",
    "            #    'body_stats': 1.0,\n",
    "            #},\n",
    "        )),\n",
    "\n",
    "        # Use a Regressor on the combined features\n",
    "        ('regressor', clf),\n",
    "    ])\n",
    "\n",
    "        model_name = \"singlelogisticregressionclassifier\"\n",
    "        #clf = sklearn.naive_bayes.MultinomialNB()\n",
    "        #train_classifiers(traincsvfile,clf)\n",
    "        #train_single_classifier(traincsvfile,pipeline,model_name)\n",
    "        predicted_labels = []\n",
    "\n",
    "\n",
    "        def f(x):\n",
    "            return float(x)\n",
    "        f = numpy.vectorize(f)\n",
    "        test_labels = f(testSet.pop('Salary'))\n",
    "        train_labels=f(trainingSet.pop('Salary'))\n",
    "        #clf.fit(trainingSet,train_labels)\n",
    "        x = pipeline.fit(trainingSet,train_labels)\n",
    "        meanvalue = numpy.mean(train_labels)\n",
    "        #predicted_labels = numpy.empty(test_labels.shape)\n",
    "        #predicted_labels.fill(meanvalue)\n",
    "        predicted_labels = pipeline.predict(testSet)\n",
    "        #predicted_labels = clf.predict(testSet)\n",
    "        #print(\"Intercept:\",clf.)\n",
    "        #print('Coefficients: \\n', clf.coef_)\n",
    "        #print('Intercept: \\n', clf.intercept_)\n",
    "\n",
    "\n",
    "        evaluate(test_labels,predicted_labels)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"C:\\\\Users\\\\Abhishek\\\\Downloads\\\\datachallenge_cods2016\\\\datachallenge_cods2016\\\\train.xlsx\"\n",
    "    main(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean square error is 57009742647.1\n",
      "The mean square error is 82687645914.4\n",
      "The mean square error is 42310441888.6\n",
      "The mean square error is 64357679738.6\n",
      "The mean square error is 34073110285.0\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'Abhishek'\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neighbors\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "from scipy.sparse import hstack,csr_matrix,isspmatrix_csr\n",
    "import re\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rb\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "def splitDataset(dataframe, splitRatio):\n",
    "    msk = np.random.rand(len(dataframe)) < splitRatio\n",
    "    train,test = dataframe[msk],dataframe[~msk]\n",
    "    return (train,test)\n",
    "def extractCollegeStateFeatures(dataframe):\n",
    "    dataValues = dataframe['CollegeState'].values\n",
    "    collegeState_set = set(dataValues)\n",
    "    collegeStateDictionary = dict(enumerate(collegeState_set))\n",
    "    collegeStateList = list(collegeState_set)\n",
    "    featureList = []\n",
    "    for i in range(0,len(dataValues)):\n",
    "        featureList.append(collegeStateList.index(dataValues[i]))\n",
    "\n",
    "    return featureList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetchLabels(dataframe,salaryBar):\n",
    "    labels = []\n",
    "\n",
    "    for salaryValue in dataframe['Salary'].values:\n",
    "        if(salaryValue<=salaryBar[0]):\n",
    "            labels.append(0)\n",
    "        elif(salaryValue>salaryBar[0] and salaryValue<salaryBar[1]):\n",
    "            labels.append(1)\n",
    "        elif(salaryValue>salaryBar[1] and salaryValue<salaryBar[2]):\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(3)\n",
    "    return labels\n",
    "\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,dataframe):\n",
    "        featureSet = []\n",
    "        collegeStateFeatureList = extractCollegeStateFeatures(dataframe)\n",
    "        count = 0\n",
    "        for index,row in dataframe.iterrows():\n",
    "\n",
    "            features = {}\n",
    "            #features['12percentage'] = row['12percentage']\n",
    "            #features['10percentage'] = row['10percentage']\n",
    "\n",
    "            #features['CollegeTier'] = row['CollegeTier']\n",
    "            #features['collegeGPA'] =row['collegeGPA']\n",
    "            features['PreUniversity'] = row[\"10percentage\"] + row[\"12percentage\"]\n",
    "            gpa = row[\"collegeGPA\"]\n",
    "            if(gpa<=10.0):\n",
    "                gpa = gpa * 10\n",
    "            features['University'] = math.pow(gpa,(1.0/(float(row['CollegeTier']) + 1.0)))\n",
    "\n",
    "\n",
    "            domain_score = -1\n",
    "            possibledomains = 'ComputerProgramming','ElectronicsAndSemicon','ComputerScience','MechanicalEngg','ElectricalEngg','TelecomEngg','CivilEngg'\n",
    "            for domain in possibledomains:\n",
    "                if(row[domain] != '-1'):\n",
    "                    domain_score = row[domain]\n",
    "                    break\n",
    "            if domain_score != -1:\n",
    "                features['AMCATscore'] = float(row['English'] + row['Logical'] + row['Quant'] + domain_score)/4.0\n",
    "                #features['AMCATscore'] = float( row['Logical'] + row['Quant'] + domain_score)/3.0\n",
    "            else:\n",
    "                features['AMCATscore'] = float(row['English']+row['Logical'] + row['Quant'])/3.0\n",
    "\n",
    "\n",
    "\n",
    "            #features['Logical'] = row['Logical']\n",
    "            #features['Quant'] = row['Quant']\n",
    "            # else:\n",
    "            #     features['Degree'] = 0\n",
    "            # if(row['Gender']=='m'):\n",
    "            #     features['Gender'] = 1\n",
    "            # else:\n",
    "            #     features['Gender'] = 0\n",
    "\n",
    "            featureSet.append(features)\n",
    "            count = count + 1\n",
    "        return featureSet\n",
    "\n",
    "def evaluate(salary_actual,salary_predicted):\n",
    "    print \"The mean square error is \"+str(mean_squared_error(salary_actual,salary_predicted))\n",
    "\n",
    "\n",
    "def main(filename):\n",
    "\n",
    "    splitRatio = 0.8\n",
    "\n",
    "    df = pd.read_excel(filename,header=0)\n",
    "\n",
    "    for i in range(0,5):\n",
    "        trainingSet, testSet = splitDataset(df, splitRatio)\n",
    "        clf = sklearn.linear_model.LogisticRegression(penalty='l1',C=0.5)\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "        # Extract the subject & body\n",
    "\n",
    "\n",
    "        # Use FeatureUnion to combine the features from subject and body\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list=[\n",
    "\n",
    "                # Pipeline for standard bag-of-words model for body\n",
    "                #('bow', Pipeline([\n",
    "                #    ('count', CountVectorizer()),\n",
    "                #    ('tfidf',TfidfTransformer()),\n",
    "                #])),\n",
    "\n",
    "                # Pipeline for pulling ad hoc features from post's body\n",
    "                ('body_stats', Pipeline([\n",
    "                    ('stats', TextStats()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "                ])),\n",
    "\n",
    "            ],\n",
    "\n",
    "            # weight components in FeatureUnion\n",
    "            #transformer_weights={\n",
    "            #    'subject': 0.8,\n",
    "            #    'body_bow': 0.5,\n",
    "            #    'body_stats': 1.0,\n",
    "            #},\n",
    "        )),\n",
    "\n",
    "        # Use a Regressor on the combined features\n",
    "        ('regressor', clf),\n",
    "    ])\n",
    "\n",
    "        model_name = \"singlelogisticregressionclassifier\"\n",
    "        #clf = sklearn.naive_bayes.MultinomialNB()\n",
    "        #train_classifiers(traincsvfile,clf)\n",
    "        #train_single_classifier(traincsvfile,pipeline,model_name)\n",
    "        predicted_labels = []\n",
    "\n",
    "\n",
    "        def f(x):\n",
    "            return float(x)\n",
    "        f = numpy.vectorize(f)\n",
    "        test_labels = f(testSet.pop('Salary'))\n",
    "        train_labels=f(trainingSet.pop('Salary'))\n",
    "        #clf.fit(trainingSet,train_labels)\n",
    "        x = pipeline.fit(trainingSet,train_labels)\n",
    "        meanvalue = numpy.mean(train_labels)\n",
    "        #predicted_labels = numpy.empty(test_labels.shape)\n",
    "        #predicted_labels.fill(meanvalue)\n",
    "        predicted_labels = pipeline.predict(testSet)\n",
    "        #predicted_labels = clf.predict(testSet)\n",
    "        #print(\"Intercept:\",clf.)\n",
    "        #print('Coefficients: \\n', clf.coef_)\n",
    "        #print('Intercept: \\n', clf.intercept_)\n",
    "\n",
    "\n",
    "        evaluate(test_labels,predicted_labels)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"C:\\\\Users\\\\Abhishek\\\\Downloads\\\\datachallenge_cods2016\\\\datachallenge_cods2016\\\\train.xlsx\"\n",
    "    main(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean square error is 41852326424.9\n",
      "The mean square error is 33348717948.7\n",
      "The mean square error is 38115686274.5\n",
      "The mean square error is 66416404282.1\n",
      "The mean square error is 27589604271.4\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'Abhishek'\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neighbors\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "from scipy.sparse import hstack,csr_matrix,isspmatrix_csr\n",
    "import re\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rb\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "def splitDataset(dataframe, splitRatio):\n",
    "    msk = np.random.rand(len(dataframe)) < splitRatio\n",
    "    train,test = dataframe[msk],dataframe[~msk]\n",
    "    return (train,test)\n",
    "def extractCollegeStateFeatures(dataframe):\n",
    "    dataValues = dataframe['CollegeState'].values\n",
    "    collegeState_set = set(dataValues)\n",
    "    collegeStateDictionary = dict(enumerate(collegeState_set))\n",
    "    collegeStateList = list(collegeState_set)\n",
    "    featureList = []\n",
    "    for i in range(0,len(dataValues)):\n",
    "        featureList.append(collegeStateList.index(dataValues[i]))\n",
    "\n",
    "    return featureList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetchLabels(dataframe,salaryBar):\n",
    "    labels = []\n",
    "\n",
    "    for salaryValue in dataframe['Salary'].values:\n",
    "        if(salaryValue<=salaryBar[0]):\n",
    "            labels.append(0)\n",
    "        elif(salaryValue>salaryBar[0] and salaryValue<salaryBar[1]):\n",
    "            labels.append(1)\n",
    "        elif(salaryValue>salaryBar[1] and salaryValue<salaryBar[2]):\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(3)\n",
    "    return labels\n",
    "\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,dataframe):\n",
    "        featureSet = []\n",
    "        collegeStateFeatureList = extractCollegeStateFeatures(dataframe)\n",
    "        count = 0\n",
    "        for index,row in dataframe.iterrows():\n",
    "\n",
    "            features = {}\n",
    "            #features['12percentage'] = row['12percentage']\n",
    "            #features['10percentage'] = row['10percentage']\n",
    "\n",
    "            #features['CollegeTier'] = row['CollegeTier']\n",
    "            #features['collegeGPA'] =row['collegeGPA']\n",
    "            features['PreUniversity'] = row[\"10percentage\"] + row[\"12percentage\"]\n",
    "            gpa = row[\"collegeGPA\"]\n",
    "            if(gpa<=10.0):\n",
    "                gpa = gpa * 10\n",
    "            features['University'] = math.pow(gpa,(1.0/(float(row['CollegeTier']) + 1.0)))\n",
    "\n",
    "\n",
    "            domain_score = -1\n",
    "            possibledomains = 'ComputerProgramming','ElectronicsAndSemicon','ComputerScience','MechanicalEngg','ElectricalEngg','TelecomEngg','CivilEngg'\n",
    "            for domain in possibledomains:\n",
    "                if(row[domain] != '-1'):\n",
    "                    domain_score = row[domain]\n",
    "                    break\n",
    "            if domain_score != -1:\n",
    "                features['AMCATscore'] = float(row['English'] + row['Logical'] + row['Quant'] + domain_score)/4.0\n",
    "                #features['AMCATscore'] = float( row['Logical'] + row['Quant'] + domain_score)/3.0\n",
    "            else:\n",
    "                features['AMCATscore'] = float(row['English']+row['Logical'] + row['Quant'])/3.0\n",
    "\n",
    "\n",
    "\n",
    "            #features['Logical'] = row['Logical']\n",
    "            #features['Quant'] = row['Quant']\n",
    "            # else:\n",
    "            #     features['Degree'] = 0\n",
    "            # if(row['Gender']=='m'):\n",
    "            #     features['Gender'] = 1\n",
    "            # else:\n",
    "            #     features['Gender'] = 0\n",
    "\n",
    "            featureSet.append(features)\n",
    "            count = count + 1\n",
    "        return featureSet\n",
    "\n",
    "def evaluate(salary_actual,salary_predicted):\n",
    "    print \"The mean square error is \"+str(mean_squared_error(salary_actual,salary_predicted))\n",
    "\n",
    "\n",
    "def main(filename):\n",
    "\n",
    "    splitRatio = 0.8\n",
    "\n",
    "    df = pd.read_excel(filename,header=0)\n",
    "\n",
    "    for i in range(0,5):\n",
    "        trainingSet, testSet = splitDataset(df, splitRatio)\n",
    "        clf = sklearn.linear_model.LogisticRegression(penalty='l1')\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "        # Extract the subject & body\n",
    "\n",
    "\n",
    "        # Use FeatureUnion to combine the features from subject and body\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list=[\n",
    "\n",
    "                # Pipeline for standard bag-of-words model for body\n",
    "                #('bow', Pipeline([\n",
    "                #    ('count', CountVectorizer()),\n",
    "                #    ('tfidf',TfidfTransformer()),\n",
    "                #])),\n",
    "\n",
    "                # Pipeline for pulling ad hoc features from post's body\n",
    "                ('body_stats', Pipeline([\n",
    "                    ('stats', TextStats()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "                ])),\n",
    "\n",
    "            ],\n",
    "\n",
    "            # weight components in FeatureUnion\n",
    "            #transformer_weights={\n",
    "            #    'subject': 0.8,\n",
    "            #    'body_bow': 0.5,\n",
    "            #    'body_stats': 1.0,\n",
    "            #},\n",
    "        )),\n",
    "\n",
    "        # Use a Regressor on the combined features\n",
    "        ('regressor', clf),\n",
    "    ])\n",
    "\n",
    "        model_name = \"singlelogisticregressionclassifier\"\n",
    "        #clf = sklearn.naive_bayes.MultinomialNB()\n",
    "        #train_classifiers(traincsvfile,clf)\n",
    "        #train_single_classifier(traincsvfile,pipeline,model_name)\n",
    "        predicted_labels = []\n",
    "\n",
    "\n",
    "        def f(x):\n",
    "            return float(x)\n",
    "        f = numpy.vectorize(f)\n",
    "        test_labels = f(testSet.pop('Salary'))\n",
    "        train_labels=f(trainingSet.pop('Salary'))\n",
    "        #clf.fit(trainingSet,train_labels)\n",
    "        x = pipeline.fit(trainingSet,train_labels)\n",
    "        meanvalue = numpy.mean(train_labels)\n",
    "        #predicted_labels = numpy.empty(test_labels.shape)\n",
    "        #predicted_labels.fill(meanvalue)\n",
    "        predicted_labels = pipeline.predict(testSet)\n",
    "        #predicted_labels = clf.predict(testSet)\n",
    "        #print(\"Intercept:\",clf.)\n",
    "        #print('Coefficients: \\n', clf.coef_)\n",
    "        #print('Intercept: \\n', clf.intercept_)\n",
    "\n",
    "\n",
    "        evaluate(test_labels,predicted_labels)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"C:\\\\Users\\\\Abhishek\\\\Downloads\\\\datachallenge_cods2016\\\\datachallenge_cods2016\\\\train.xlsx\"\n",
    "    main(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean square error is 61075234200.4\n",
      "The mean square error is 37266453359.4\n",
      "The mean square error is 43686648120.2\n",
      "The mean square error is 52519870596.3\n",
      "The mean square error is 29575823729.1\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'Abhishek'\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neighbors\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "from scipy.sparse import hstack,csr_matrix,isspmatrix_csr\n",
    "import re\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rb\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "def splitDataset(dataframe, splitRatio):\n",
    "    msk = np.random.rand(len(dataframe)) < splitRatio\n",
    "    train,test = dataframe[msk],dataframe[~msk]\n",
    "    return (train,test)\n",
    "def extractCollegeStateFeatures(dataframe):\n",
    "    dataValues = dataframe['CollegeState'].values\n",
    "    collegeState_set = set(dataValues)\n",
    "    collegeStateDictionary = dict(enumerate(collegeState_set))\n",
    "    collegeStateList = list(collegeState_set)\n",
    "    featureList = []\n",
    "    for i in range(0,len(dataValues)):\n",
    "        featureList.append(collegeStateList.index(dataValues[i]))\n",
    "\n",
    "    return featureList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetchLabels(dataframe,salaryBar):\n",
    "    labels = []\n",
    "\n",
    "    for salaryValue in dataframe['Salary'].values:\n",
    "        if(salaryValue<=salaryBar[0]):\n",
    "            labels.append(0)\n",
    "        elif(salaryValue>salaryBar[0] and salaryValue<salaryBar[1]):\n",
    "            labels.append(1)\n",
    "        elif(salaryValue>salaryBar[1] and salaryValue<salaryBar[2]):\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(3)\n",
    "    return labels\n",
    "\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,dataframe):\n",
    "        featureSet = []\n",
    "        collegeStateFeatureList = extractCollegeStateFeatures(dataframe)\n",
    "        count = 0\n",
    "        for index,row in dataframe.iterrows():\n",
    "\n",
    "            features = {}\n",
    "            #features['12percentage'] = row['12percentage']\n",
    "            #features['10percentage'] = row['10percentage']\n",
    "\n",
    "            #features['CollegeTier'] = row['CollegeTier']\n",
    "            #features['collegeGPA'] =row['collegeGPA']\n",
    "            features['PreUniversity'] = row[\"10percentage\"] + row[\"12percentage\"]\n",
    "            gpa = row[\"collegeGPA\"]\n",
    "            if(gpa<=10.0):\n",
    "                gpa = gpa * 10\n",
    "            features['University'] = math.pow(gpa,(1.0/(float(row['CollegeTier']) + 1.0)))\n",
    "\n",
    "\n",
    "            domain_score = -1\n",
    "            possibledomains = 'ComputerProgramming','ElectronicsAndSemicon','ComputerScience','MechanicalEngg','ElectricalEngg','TelecomEngg','CivilEngg'\n",
    "            for domain in possibledomains:\n",
    "                if(row[domain] != '-1'):\n",
    "                    domain_score = row[domain]\n",
    "                    break\n",
    "            if domain_score != -1:\n",
    "                features['AMCATscore'] = float(row['English'] + row['Logical'] + row['Quant'] + domain_score)/4.0\n",
    "                #features['AMCATscore'] = float( row['Logical'] + row['Quant'] + domain_score)/3.0\n",
    "            else:\n",
    "                features['AMCATscore'] = float(row['English']+row['Logical'] + row['Quant'])/3.0\n",
    "\n",
    "\n",
    "\n",
    "            #features['Logical'] = row['Logical']\n",
    "            #features['Quant'] = row['Quant']\n",
    "            # else:\n",
    "            #     features['Degree'] = 0\n",
    "            # if(row['Gender']=='m'):\n",
    "            #     features['Gender'] = 1\n",
    "            # else:\n",
    "            #     features['Gender'] = 0\n",
    "\n",
    "            featureSet.append(features)\n",
    "            count = count + 1\n",
    "        return featureSet\n",
    "\n",
    "def evaluate(salary_actual,salary_predicted):\n",
    "    print \"The mean square error is \"+str(mean_squared_error(salary_actual,salary_predicted))\n",
    "\n",
    "\n",
    "def main(filename):\n",
    "\n",
    "    splitRatio = 0.8\n",
    "\n",
    "    df = pd.read_excel(filename,header=0)\n",
    "\n",
    "    for i in range(0,5):\n",
    "        trainingSet, testSet = splitDataset(df, splitRatio)\n",
    "        clf = RandomForestRegressor(n_estimators = 75)\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "        # Extract the subject & body\n",
    "\n",
    "\n",
    "        # Use FeatureUnion to combine the features from subject and body\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list=[\n",
    "\n",
    "                # Pipeline for standard bag-of-words model for body\n",
    "                #('bow', Pipeline([\n",
    "                #    ('count', CountVectorizer()),\n",
    "                #    ('tfidf',TfidfTransformer()),\n",
    "                #])),\n",
    "\n",
    "                # Pipeline for pulling ad hoc features from post's body\n",
    "                ('body_stats', Pipeline([\n",
    "                    ('stats', TextStats()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "                ])),\n",
    "\n",
    "            ],\n",
    "\n",
    "            # weight components in FeatureUnion\n",
    "            #transformer_weights={\n",
    "            #    'subject': 0.8,\n",
    "            #    'body_bow': 0.5,\n",
    "            #    'body_stats': 1.0,\n",
    "            #},\n",
    "        )),\n",
    "\n",
    "        # Use a Regressor on the combined features\n",
    "        ('regressor', clf),\n",
    "    ])\n",
    "\n",
    "        model_name = \"singlelogisticregressionclassifier\"\n",
    "        #clf = sklearn.naive_bayes.MultinomialNB()\n",
    "        #train_classifiers(traincsvfile,clf)\n",
    "        #train_single_classifier(traincsvfile,pipeline,model_name)\n",
    "        predicted_labels = []\n",
    "\n",
    "\n",
    "        def f(x):\n",
    "            return float(x)\n",
    "        f = numpy.vectorize(f)\n",
    "        test_labels = f(testSet.pop('Salary'))\n",
    "        train_labels=f(trainingSet.pop('Salary'))\n",
    "        #clf.fit(trainingSet,train_labels)\n",
    "        x = pipeline.fit(trainingSet,train_labels)\n",
    "        meanvalue = numpy.mean(train_labels)\n",
    "        #predicted_labels = numpy.empty(test_labels.shape)\n",
    "        #predicted_labels.fill(meanvalue)\n",
    "        predicted_labels = pipeline.predict(testSet)\n",
    "        #predicted_labels = clf.predict(testSet)\n",
    "        #print(\"Intercept:\",clf.)\n",
    "        #print('Coefficients: \\n', clf.coef_)\n",
    "        #print('Intercept: \\n', clf.intercept_)\n",
    "\n",
    "\n",
    "        evaluate(test_labels,predicted_labels)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"C:\\\\Users\\\\Abhishek\\\\Downloads\\\\datachallenge_cods2016\\\\datachallenge_cods2016\\\\train.xlsx\"\n",
    "    main(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
